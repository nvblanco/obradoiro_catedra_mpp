{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fa60e6d8",
   "metadata": {},
   "source": [
    "<center><h1>Obradoiro: Como aprenden as máquinas a partir de datos</h1></center>\n",
    "\n",
    "<center><img src=\"https://camelia.usc.gal/rs/logo-camelia-top.svg\" width=\"600px\"></center>\n",
    "<br>\n",
    "<center>Brais Castiñeiras ✉️ <a href= \"mailto:brais.castineirasgaldo@plexus.es\">brais.castineirasgaldo@plexus.es</a></center>\n",
    "<center>Nicolás Vila ✉️ <a href= \"mailto:nicolas.vila@usc.es\">nicolas.vila@usc.es</a></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f76ee866",
   "metadata": {},
   "source": [
    "## Aprendizaxe automática e medicina\n",
    "\n",
    "A **aprendizaxe automática** (*machine learning*) é unha rama da intelixencia artificial que permite desenvolver sistemas capaces de aprender a partir de datos e mellorar o seu rendemento sen seren programados explicitamente. No contexto médico, isto significa que os algoritmos poden analizar grandes volumes de información —como imaxes médicas, rexistros electrónicos de saúde ou datos xenéticos— para identificar patróns, facer predicións ou asistir no diagnóstico e no tratamento.\n",
    "\n",
    "Na práctica, a aprendizaxe automática está a cambiar a medicina en moitos ámbitos. Por exemplo, xa se usa para detectar enfermidades en fases temperás mediante a análise de imaxes de raios X, resonancias magnéticas ou fotografías dermatolóxicas. Tamén se emprega para predicir riscos de complicacións, personalizar tratamentos segundo o perfil de cada paciente, ou mesmo para optimizar a xestión hospitalaria. A súa capacidade para procesar datos complexos e atopar relacións permite aos profesionais da saúde aforrar tempo e mellorar os resultados.\n",
    "\n",
    "Existen dous grandes enfoques principais dentro da aprendizaxe automática: a **aprendizaxe supervisada** e a **aprendizaxe non supervisada**.\n",
    "\n",
    "- Na **aprendizaxe supervisada**, o modelo é adestrado con datos de entrada aos que se lles asocia unha resposta coñecida (como o diagnóstico dunha enfermidade ou a evolución dun parámetro clínico). É o caso típico de predición ou clasificación, e inclúe modelos como regresións, árbores de decisión ou redes neuronais. Exemplos comúns na medicina inclúen a predición da probabilidade de reingreso hospitalario ou a clasificación de imaxes como benignas ou malignas. No exemplo inferior, vemos como un modelo se adestra para predicir se un paciente está enfermo a partir da súa masa muscular e as horas semanais de exercicio.\n",
    "\n",
    "<center><img src=\"images/aa_supervisada.png\" width=\"800px\"></center>\n",
    "\n",
    "- Na **aprendizaxe non supervisada**, o sistema trata de descubrir estruturas ou patróns ocultos en datos sen etiquetas previas. Este enfoque é útil, por exemplo, para segmentar pacientes en grupos con características clínicas similares ou para detectar anomalías nos sinais vitais que poidan indicar un problema de saúde non diagnosticado. Os métodos máis típicos son, entre outros, o agrupamento (*clustering*) e a redución de dimensións (como PCA). No exemplo inferior, vemos como un modelo é capaz de agrupar pacientes en 3 grupos de acordo ás súas similaridades de masa muscular e horas semanais de exercicio, o cal pode ser útil para facer recomendacións personalizadas de exercicio físico ou distintos tratamentos ante certas patoloxías.\n",
    "\n",
    "<center><img src=\"images/aa_non_supervisada.png\" width=\"500px\"></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "574238ca",
   "metadata": {},
   "source": [
    "## Modelos de regresión\n",
    "\n",
    "Os **modelos de regresión** son un tipo de algoritmo de aprendizaxe automática supervisada que se utiliza para predicir valores numéricos continuos a partir de datos de entrada. A súa principal finalidade é establecer unha relación entre unha ou varias variables independentes (por exemplo, idade, presión arterial, nivel de glicosa) e unha variable dependente (como pode ser a duración dunha estancia hospitalaria ou o nivel de risco dun paciente).\n",
    "\n",
    "Na medicina, os modelos de regresión son amplamente utilizados para tarefas como:\n",
    "- **Predición da duración da hospitalización** segundo factores clínicos e demográficos.\n",
    "- **Estimación da probabilidade de supervivencia** en pacientes con enfermidades crónicas ou agudas.\n",
    "- **Cálculo da dose óptima dun medicamento**, en función das características individuais do paciente.\n",
    "- **Modelado do progreso dunha enfermidade**, como a evolución dos niveis de HbA1c en persoas con diabetes.\n",
    "\n",
    "## Regresión lineal\n",
    "\n",
    "A **regresión lineal** é un dos modelos estatísticos máis sinxelos e utilizados dentro da aprendizaxe automática supervisada. Permite modelar a relación entre unha ou máis variables independentes (ou características) e unha variable dependente (ou resposta), asumindo que esta relación é lineal.\n",
    "\n",
    "A fórmula da regresión lineal simple (cunha soa variable preditora) é:\n",
    "\n",
    "$$\n",
    "y = \\beta_0 + \\beta_1 x\n",
    "$$\n",
    "\n",
    "Onde:\n",
    "- $y$ é a variable que se quere predicir (dependente)\n",
    "- $x$ é a variable preditora (independente)\n",
    "- $\\beta_0$ é o termo independente ou constante (intercepto)\n",
    "- $\\beta_1$ é o coeficiente que representa o efecto de $x$ sobre $y$\n",
    "\n",
    "Por exemplo, un posible modelo para predicir o tempo de recuperación dunha lesión (en días) a partir da idade do paciente (en anos), a fórmula podería ser:\n",
    "\n",
    "$$\n",
    "\\text{Tempo\\_recuperación} = \\beta_0 + \\beta_1 \\cdot \\text{Idade}\n",
    "$$\n",
    "\n",
    "Se no caso anterior $\\beta_0=10$ e $\\beta_1=0.1$, o tempo de recuperación estimado sería de $10$ días, máis $0.1$ días adicionais por cada ano do paciente. Para un paciente de 30 anos, o tempo estimado de recuperación sería de $10 + 0.1 \\cdot 30 = 13$ días.\n",
    "\n",
    "Para ver un caso práctico, imos primeiro a simular un conxunto de datos que represente a idade dos pacientes e o tempo de recuperación dunha lesión."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48cde10b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "np.random.seed(42)\n",
    "ages = np.random.randint(18, 80, 50)\n",
    "recovery_times = 11 + 0.08 * ages + np.random.normal(0, 0.5, 50)\n",
    "\n",
    "plt.scatter(ages, recovery_times, color='blue', label='Datos reais')\n",
    "plt.xlabel('Idade do paciente (anos)')\n",
    "plt.ylabel('Tempo de recuperación (días)')\n",
    "plt.title('Idade vs Tempo de recuperación')\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff3e9932",
   "metadata": {},
   "source": [
    "Ahora imos ver que tal se comporta un modelo de regresión cos parámetros mencionados anteriormente ($\\beta_0=10$ e $\\beta_1=0.1$) e como se comporta ante os datos simulados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8983bb51",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = ages.reshape(-1, 1) \n",
    "y = recovery_times\n",
    "\n",
    "beta_0 = 10\n",
    "beta_1 = 0.1\n",
    "\n",
    "xlim = (15, 85)\n",
    "ylim = (10, 20)\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.scatter(ages, recovery_times, alpha=0.6, color='blue', label='Datos de adestramento')\n",
    "\n",
    "plt.plot(ages, beta_0 + beta_1 * ages, color='red', linewidth=2, label=rf'$\\beta_0 = {beta_0}, \\beta_1 = {beta_1}$')\n",
    "\n",
    "new_patient_age = 30\n",
    "predicted_recovery_time = beta_0 + beta_1 * new_patient_age\n",
    "\n",
    "plt.plot((new_patient_age, new_patient_age), (ylim[0], predicted_recovery_time), color='green', linestyle='--', label=f'Novo paciente (Idade = {new_patient_age})\\nTempo estimado de recuperación = {predicted_recovery_time:.2f} días')\n",
    "plt.scatter(new_patient_age, predicted_recovery_time, color='green', s=100, edgecolor='black', zorder=5)\n",
    "plt.plot((xlim[0], new_patient_age), (predicted_recovery_time, predicted_recovery_time), color='green', linestyle='--')\n",
    "\n",
    "plt.xlim(xlim)\n",
    "plt.ylim(ylim)\n",
    "plt.xlabel('Idade (anos)')\n",
    "plt.ylabel('Tempo de recuperación (días)')\n",
    "plt.title('Predición do tempo de recuperación segundo a idade do paciente (bo axuste)')\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fa6598b",
   "metadata": {},
   "source": [
    "Como vemos, este modelo é capaz de capturar a tendencia dos datos (aumento do tempo de recuperación co aumento da idade), pero evidentemente non é perfecto, xa que hai variacións e erros aleatorios que non se poden explicar só pola idade.\n",
    "\n",
    "Ahora imos ver que pasaría se cambiamos os parámetros do modelo, por exemplo, aumentando $\\beta_1$ a $0.08$. Isto significa que o modelo asume que o tempo de recuperación aumenta máis lentamente co aumento da idade."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8241be35",
   "metadata": {},
   "outputs": [],
   "source": [
    "beta_0 = 14\n",
    "beta_1 = 0.05\n",
    "\n",
    "xlim = (15, 85)\n",
    "ylim = (10, 20)\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.scatter(ages, recovery_times, alpha=0.6, color='blue', label='Datos de adestramento')\n",
    "\n",
    "plt.plot(ages, beta_0 + beta_1 * ages, color='red', linewidth=2, label=rf'$\\beta_0 = {beta_0}, \\beta_1 = {beta_1}$')\n",
    "\n",
    "new_patient_age = 30\n",
    "predicted_recovery_time = beta_0 + beta_1 * new_patient_age\n",
    "\n",
    "plt.plot((new_patient_age, new_patient_age), (ylim[0], predicted_recovery_time), color='green', linestyle='--', label=f'Novo paciente (Idade = {new_patient_age})\\nTempo estimado de recuperación = {predicted_recovery_time:.2f} días')\n",
    "plt.scatter(new_patient_age, predicted_recovery_time, color='green', s=100, edgecolor='black', zorder=5)\n",
    "plt.plot((xlim[0], new_patient_age), (predicted_recovery_time, predicted_recovery_time), color='green', linestyle='--')\n",
    "\n",
    "plt.xlim(xlim)\n",
    "plt.ylim(ylim)\n",
    "plt.xlabel('Idade (anos)')\n",
    "plt.ylabel('Tempo de recuperación (días)')\n",
    "plt.title('Predición do tempo de recuperación segundo a idade do paciente (mal axuste)')\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff254ad8",
   "metadata": {},
   "source": [
    "Como vemos, este modelo compórtase moito peor que o anterior, xa que os erros de predición son maiores. Concretamente, a predición sobreestima sistemáticamente o tempo de recuperación."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39a1a608",
   "metadata": {},
   "source": [
    "### Como facemos o axuste automáticamente?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4124127",
   "metadata": {},
   "source": [
    "Para calcular os parámetros óptimos do modelo de regresión lineal, podemos utilizar a biblioteca `scikit-learn`, que é unha das máis populares en Python para tarefas de aprendizaxe automática. Esta biblioteca proporciona unha implementación eficiente do algoritmo de regresión lineal, que axusta os parámetros do modelo minimizando o erro cuadrático medio entre as predicións e os valores reais."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6de8e300",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "# Poñemos os datos en formato adecuado para o modelo\n",
    "# X debe ser unha matriz na que cada fila correspóndese a un exemplo de adestramento (neste caso, un paciente) e cada columna a unha característica dese exemplo (neste caso, a idade)\n",
    "# Y debe ser un vector cos valores de saída para cada exemplo (tempos de recuperación)\n",
    "X = ages.reshape(-1, 1) \n",
    "Y = recovery_times\n",
    "\n",
    "# Creamos o modelo de regresión lineal\n",
    "model = LinearRegression()\n",
    "# Axustámolo aos datos de adestramento\n",
    "model.fit(X, Y)\n",
    "# Obtemos os parámetros do modelo axustado\n",
    "beta_0 = model.intercept_\n",
    "beta_1 = model.coef_[0]\n",
    "\n",
    "xlim = (15, 85)\n",
    "ylim = (10, 20)\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "# Amosamos os datos de adestramento e a liña de regresión axustada\n",
    "plt.scatter(ages, recovery_times, alpha=0.6, color='blue', label='Datos de adestramento')\n",
    "plt.plot(ages, beta_0 + beta_1 * ages, color='red', linewidth=2, label=rf'$\\beta_0 = {beta_0:.2f}, \\beta_1 = {beta_1:.2f}$')\n",
    "\n",
    "# Ahora imos predecir o tempo de recuperación para un novo paciente cunha idade de 30 anos\n",
    "# Para utilizar a función de predición do modelo, necesitamos que a idade do paciente tamén estea en formato de matriz\n",
    "# A idade do novo paciente debe ser un array bidimensional, aínda que só teña un valor\n",
    "# Por iso, usamos np.array([[30]]) para crear un array de 2D con un só elemento\n",
    "new_patient_age = 30\n",
    "X_new = np.array([[new_patient_age]])\n",
    "# Facemos a predición do tempo de recuperación para o novo paciente\n",
    "# A función predict do modelo devolve un array cas predicións, así que obtemos o primeiro elemento para obter o valor escalar\n",
    "predicted_recovery_time = model.predict(X_new)[0] # Esto sería o mesmo que calcular (beta_0 + beta_1 * new_patient_age)\n",
    "\n",
    "plt.plot((new_patient_age, new_patient_age), (ylim[0], predicted_recovery_time), color='green', linestyle='--', label=f'Novo paciente (Idade = {new_patient_age})\\nTempo estimado de recuperación = {predicted_recovery_time:.2f} días')\n",
    "plt.scatter(new_patient_age, predicted_recovery_time, color='green', s=100, edgecolor='black', zorder=5)\n",
    "plt.plot((xlim[0], new_patient_age), (predicted_recovery_time, predicted_recovery_time), color='green', linestyle='--')\n",
    "\n",
    "plt.xlim(xlim)\n",
    "plt.ylim(ylim)\n",
    "plt.xlabel('Idade (anos)')\n",
    "plt.ylabel('Tempo de recuperación (días)')\n",
    "plt.title('Predición do tempo de recuperación segundo a idade do paciente (axuste automático)')\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55ce7af7",
   "metadata": {},
   "source": [
    "### Como sabemos se o modelo se vai comportar ben con datos futuros?\n",
    "\n",
    "Cando desenvolvemos un modelo de aprendizaxe automática, o noso obxectivo último é que se comporte ben en datos futuros. A fin de contas, no conxunto de adestramento xa coñecemos o valor da variable a predicir. Para facer un axuste o máis robusto posible, hai que reservar parte dos datos de adestramento para a validación final, de tal maneira que estes non tomen parte no adestramento (axuste) do modelo. Deste xeito simularemos unhas condicións o máis realistas posibles.\n",
    "\n",
    "Unha vez axustado o modelo de xeito automático, podemos realizar as predicións para cada dato de validación directamente coa función `predict()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b293808",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Dividimos os datos en conxuntos de adestramento e validación\n",
    "# Utilizamos un 80% dos datos para o adestramento e un 20% para a validación final, e fixamos a semente aleatoria para reproducibilidade\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Creamos e axustamos o modelo de regresión lineal cos datos de adestramento\n",
    "model = LinearRegression()\n",
    "model.fit(X_train, Y_train)\n",
    "beta_0 = model.intercept_\n",
    "beta_1 = model.coef_[0]\n",
    "\n",
    "xlim = (15, 85)\n",
    "ylim = (10, 20)\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.scatter(X_train, Y_train, alpha=0.6, color='blue', label='Datos de adestramento')\n",
    "plt.scatter(X_test, Y_test, alpha=0.6, color='orange', label='Datos de validación')\n",
    "plt.plot(X_train, beta_0 + beta_1 * X_train, color='red', linewidth=2, label=rf'$\\beta_0 = {beta_0:.2f}, \\beta_1 = {beta_1:.2f}$')\n",
    "\n",
    "# Agora imos predecir o tempo de recuperación para cada paciente no conxunto de validación\n",
    "predicted_recovery_times = model.predict(X_test)\n",
    "# Para cada paciente no conxunto de validación, obtemos a idade (x), o tempo real de recuperación (y) e o tempo de recuperación predicido (predicted_recovery_time)\n",
    "for x,y,predicted_recovery_time in zip(X_test, Y_test, predicted_recovery_times):\n",
    "    # Representamos a predición e unha liña vertical que indica o erro cometido\n",
    "    plt.plot((x, x), (y, predicted_recovery_time), color='green', linestyle='--')\n",
    "    plt.scatter(x, predicted_recovery_time, color='green', s=50, edgecolor='black', zorder=5)\n",
    "\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c56cb9b8",
   "metadata": {},
   "source": [
    "Como os valores do tempo de recuperación destes datos son coñecidos (recordade que os *separamos* do conxunto de adestramento), podémolos utilizar para calcular o erro cometido na predición e así simular que pasaría con novos datos futuros.\n",
    "\n",
    "Para elo existen distintas métricas de erro. Supoñendo que temos un modelo que predí $Y$ a partir de $X$, e que temos $n$ observacións, onde $Y_i$ son os valores reais e $\\hat{Y}_i$ son as predicións do modelo para cada observación $i$:\n",
    "\n",
    "- Erro absoluto medio (MAE, *mean absolute error*): é a media das diferenzas absolutas entre os valores reais e as predicións do modelo. Indica a cantidade media de erro en unidades da variable dependente.\n",
    "$$\n",
    "MAE = \\frac{1}{n} \\sum_{i=1}^{n} |Y_i - \\hat{Y}_i|\n",
    "$$\n",
    "- Erro cadrático medio (MSE, *mean squared error*): é a media dos cadrados das diferenzas entre os valores reais e as predicións do modelo. Penaliza máis os erros grandes que o MAE.\n",
    "$$MSE = \\frac{1}{n} \\sum_{i=1}^{n} (Y_i - \\hat{Y}_i)^2$$\n",
    "- Raíz do erro cadrático medio (RMSE, *root mean squared error*): é a raíz cadrada do MSE. Permite interpretar o erro en unidades da variable dependente, o que facilita a súa interpretación.\n",
    "$$RMSE = \\sqrt{MSE} = \\sqrt{\\frac{1}{n} \\sum_{i=1}^{n} (Y_i - \\hat{Y}_i)^2}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f969328b",
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_recovery_times = model.predict(X_test) # Internamente isto fai beta_0 + beta_1 * X_test\n",
    "error = Y_test - predicted_recovery_times\n",
    "\n",
    "mae = np.mean(np.abs(error))\n",
    "mse = np.mean(error ** 2)\n",
    "rmse = np.sqrt(mse)\n",
    "\n",
    "print(f\"Erro absoluto medio (MAE): {mae:.2f} días\")\n",
    "print(f\"Erro cadrático medio (MSE): {mse:.2f}\")\n",
    "print(f\"Raíz do erro cadrático medio (RMSE): {rmse:.2f} días\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2eddd3d5",
   "metadata": {},
   "source": [
    "Comparando os valores destas métricas entre distintos modelos, podemos determinar cal é o que mellor se adapta aos datos e, polo tanto, o que probablemente se comportará mellor con datos futuros. Vamos facer as predicións cos modelos anteriores e calcular as métricas de erro.\n",
    "\n",
    "- Modelo 1: $\\beta_0=10$ e $\\beta_1=0.1$\n",
    "- Modelo 2: $\\beta_0=14$ e $\\beta_1=0.05$\n",
    "- Modelo 3 : $\\beta_0=11.71$ e $\\beta_1=0.07$ (valores axustados automaticamente)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4eea8f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creamos os valores beta_0 e beta_1 para os modelos 1, 2 e 3\n",
    "beta_0_model_1 = 10.0\n",
    "beta_1_model_1 = 0.1\n",
    "\n",
    "beta_0_model_2 = 14.0\n",
    "beta_1_model_2 = 0.05\n",
    "\n",
    "beta_0_model_3 = model.intercept_\n",
    "beta_1_model_3 = model.coef_[0]\n",
    "\n",
    "# Agora imos calcular as métricas de erro para cada modelo\n",
    "predictions_model_1 = beta_0_model_1 + beta_1_model_1 * X_test\n",
    "predictions_model_2 = beta_0_model_2 + beta_1_model_2 * X_test\n",
    "predictions_model_3 = beta_0_model_3 + beta_1_model_3 * X_test\n",
    "\n",
    "# Calculamos os erros para cada modelo\n",
    "errors_model_1 = Y_test - predictions_model_1\n",
    "errors_model_2 = Y_test - predictions_model_2\n",
    "errors_model_3 = Y_test - predictions_model_3\n",
    "\n",
    "# Calculamos as métricas de erro para cada modelo\n",
    "mae_model_1 = np.mean(np.abs(errors_model_1))\n",
    "mae_model_2 = np.mean(np.abs(errors_model_2))\n",
    "mae_model_3 = np.mean(np.abs(errors_model_3))\n",
    "mse_model_1 = np.mean(errors_model_1 ** 2)\n",
    "mse_model_2 = np.mean(errors_model_2 ** 2)\n",
    "mse_model_3 = np.mean(errors_model_3 ** 2)\n",
    "rmse_model_1 = np.sqrt(mse_model_1)\n",
    "rmse_model_2 = np.sqrt(mse_model_2)\n",
    "rmse_model_3 = np.sqrt(mse_model_3)\n",
    "\n",
    "print(f\"Modelo 1 - MAE: {mae_model_1:.2f}, MSE: {mse_model_1:.2f}, RMSE: {rmse_model_1:.2f}\")\n",
    "print(f\"Modelo 2 - MAE: {mae_model_2:.2f}, MSE: {mse_model_2:.2f}, RMSE: {rmse_model_2:.2f}\")\n",
    "print(f\"Modelo 3 - MAE: {mae_model_3:.2f}, MSE: {mse_model_3:.2f}, RMSE: {rmse_model_3:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24dcf048",
   "metadata": {},
   "source": [
    "### Que pasa cando temos máis dunha variable independente?\n",
    "\n",
    "O funcionamento básico da regresión lineal non cambia cando temos máis dunha variable independente. A fórmula xeral para a regresión lineal múltiple é:\n",
    "\n",
    "$$y = \\beta_0 + \\beta_1 x_1 + \\beta_2 x_2 + ... + \\beta_n x_n$$\n",
    "Onde:\n",
    "- $y$ é a variable dependente que queremos predicir.\n",
    "- $x_1, x_2, ..., x_n$ son as variables independentes\n",
    "- $\\beta_0$ é o termo independente ou constante (intercepto).\n",
    "- $\\beta_1, \\beta_2, ..., \\beta_n$ son os coeficientes que representan o efecto de cada variable independente sobre a variable dependente.\n",
    "\n",
    "Por exemplo, se queremos predicir o tempo de recuperación dunha lesión a partir da idade do paciente e das horas de exercicio físico que realiza ao día, a fórmula podería ser:\n",
    "$$\\text{Tempo\\_recuperación} = \\beta_0 + \\beta_1 \\cdot \\text{Idade} + \\beta_2 \\cdot \\text{Horas\\_exercicio}$$\n",
    "\n",
    "O axuste dos modelos, o cálculo das predicións e a avaliación do erro realízanse de xeito semellante ao caso da regresión lineal simple. A principal diferenza é que agora temos máis coeficientes ($\\beta_1, \\beta_2, ..., \\beta_n$) que estimar, o que pode facer que o modelo sexa máis complexo e requira máis datos para un axuste adecuado.\n",
    "\n",
    "O aspecto onde máis se nota a diferenza é na visualización dos resultados. Se temos unha variable independente, podemos representar os datos nunha gráfica bidimensional, onde o modelo de regresión é unha liña recta. Se temos dúas variables independentes, podemos representar os datos nunha gráfica tridimensional, onde o modelo de regresión é un plano. Se temos máis de dúas variables independentes, a visualización xa non é tan sinxela, pero o modelo segue sendo unha extensión da regresión lineal simple.\n",
    "\n",
    "No exemplo que vemos a continuación, imos axustar o modelo con dúas variables independentes mencionadas anteriormente: a idade do paciente e as horas de exercicio físico que realiza ao día. O modelo predicirá o tempo de recuperación da lesión en días.\n",
    "\n",
    "En primeiro lugar, creamos un conxunto de datos simulado."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "994e2d2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "ages = np.random.randint(18, 80, 50)\n",
    "exercise_hours_per_day = np.random.randint(1, 5, 50)\n",
    "recovery_times = 11 + 0.08 * ages + (-0.1) * exercise_hours_per_day + np.random.normal(0, 0.5, 50)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bd4eb57",
   "metadata": {},
   "source": [
    "Ahora creamos e axustamos o modelo de regresión lineal múltiple."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a48403ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combinamos as dúas variables independentes na matriz X\n",
    "X = np.column_stack((ages, exercise_hours_per_day))\n",
    "Y = recovery_times \n",
    "model = LinearRegression()\n",
    "model.fit(X, Y)\n",
    "# Obtemos os parámetros de modelo axustado (ahora temos un máis)\n",
    "beta_0 = model.intercept_\n",
    "beta_1 = model.coef_[0]\n",
    "beta_2 = model.coef_[1]\n",
    "\n",
    "# O que vén a continuación é a creación dunha superficie 3D que representa o modelo de regresión lineal múltiple, non é preciso entender todo o código\n",
    "\n",
    "age_range = np.linspace(15, 85, 20)\n",
    "exercise_range = np.linspace(1, 5, 20)\n",
    "age_grid, exercise_grid = np.meshgrid(age_range, exercise_range)\n",
    "recovery_grid = beta_0 + beta_1 * age_grid + beta_2 * exercise_grid\n",
    "\n",
    "import plotly.graph_objects as go\n",
    "\n",
    "scatter = go.Scatter3d(\n",
    "    x=ages, \n",
    "    y=exercise_hours_per_day, \n",
    "    z=recovery_times,\n",
    "    mode='markers',\n",
    "    marker=dict(size=6, color='blue', opacity=0.7),\n",
    "    name='Datos de adestramento'\n",
    ")\n",
    "\n",
    "surface = go.Surface(\n",
    "    x=age_grid,\n",
    "    y=exercise_grid,\n",
    "    z=recovery_grid,\n",
    "    colorscale='Reds',\n",
    "    opacity=0.3,\n",
    "    name='Plano de regresión',\n",
    "    showscale=False\n",
    ")\n",
    "\n",
    "fig = go.Figure(data=[scatter, surface])\n",
    "\n",
    "fig.update_layout(\n",
    "    title=f'Predición do tempo de recuperación<br>β₀ = {beta_0:.2f}, β₁ = {beta_1:.2f}, β₂ = {beta_2:.2f}',\n",
    "    scene=dict(\n",
    "        xaxis_title='Idade (anos)',\n",
    "        yaxis_title='Horas de exercicio por día',\n",
    "        zaxis_title='Tempo de recuperación (días)'\n",
    "    ),\n",
    "    width=800,\n",
    "    height=600\n",
    ")\n",
    "\n",
    "# Show the interactive plot\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "750ec250",
   "metadata": {},
   "source": [
    "### Exemplo práctico\n",
    "\n",
    "No próximo exemplo, traballaremos cun conxunto de datos público no que se recolle a información proporcionada por unha aseguradora sobre os seus clientes. O conxunto de datos inclúe variables como a idade, o sexo, o índice de masa corporal (IMC), o número de fillos, a zona xeográfica e o custo do seguro médico anual. O obxectivo é desenvolver un modelo de regresión lineal múltiple que prediga o custo do seguro médico anual en función das outras variables.\n",
    "\n",
    "O primeiro que imos facer é cargar o conxunto de datos e explorar as súas características. A continuación, axustaremos un modelo de regresión lineal múltiple e avaliaremos o seu rendemento utilizando as métricas de erro mencionadas anteriormente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30ee7793",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "dataset = pd.read_csv(\"datasets/insurance/insurance.csv\")\n",
    "dataset.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fef2b9bb",
   "metadata": {},
   "source": [
    "As variables deste dataset son:\n",
    "- `age`: Idade do cliente (en anos)\n",
    "- `sex`: Sexo do cliente (masculino ou feminino)\n",
    "- `bmi`: Índice de masa corporal (IMC)\n",
    "- `children`: Número de fillos do cliente\n",
    "- `region`: Zona xeográfica do cliente (noroeste, suroeste, nordeste, suroeste)\n",
    "- `smoker`: Estado de fumador do cliente (si ou non)\n",
    "- `charges`: Custo do seguro médico anual (en dólares). Esta é a variable que imos predicir."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a23f8b8",
   "metadata": {},
   "source": [
    "O primeiro problema que nos atopamos é que o conxunto de datos ten variables categóricas (como o sexo, a zona xeográfica ou o estado de fumador) que non podemos usar directamente no modelo de regresión lineal. Para iso, imos utilizar a técnica de codificación *one-hot encoding* (tamén coñecido como as variables *dummy*), que converte as variables categóricas en variables binarias (0 ou 1) que representan a presenza ou ausencia de cada categoría."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5f7e71c",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = pd.get_dummies(dataset, columns=['sex', 'region', 'smoker'], drop_first=True)\n",
    "dataset.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2cbd700",
   "metadata": {},
   "source": [
    "Se nos fixamos na táboa anterior, vemos que para cada variable categórica, se crean tantas columnas como categorías menos unha. Por exemplo, para a variable `sex`, creamos unha columna `sex_male` que toma o valor 1 se o cliente é masculino. Se a columna vale 0, o cliente é da categoría restante, é dicir, `sex_female`. Para a variable `region`, creamos catro columnas: `region_northwest`, `region_southeast` e `region_southwest`. Se as tres columnas valen 0, o cliente é da rexión restante, é dicir, `region_northeast`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05867bfa",
   "metadata": {},
   "source": [
    "Ahora imos axustar o modelo de regresión lineal seguindo os pasos que vimos anteriormente:\n",
    "\n",
    "1. Separamos as variables independentes (predictoras) e a variable dependente (a que queremos predicir)\n",
    "2. Dividimos os datos en conxunto de adestramento e conxunto de validación (test)\n",
    "3. Creamos o modelo de regresión lineal e axustámolo cos datos de adestramento\n",
    "4. Facemos as predicións para o conxunto de validación\n",
    "5. Calculamos as métricas de erro (MAE, MSE, RMSE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c62799c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# O conxunto de variables independentes (X) inclúe todas as columnas excepto 'charges', que é a variable dependente (y)\n",
    "X = dataset.drop('charges', axis=1)\n",
    "y = dataset['charges']\n",
    "\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "model = LinearRegression()\n",
    "model.fit(X_train, Y_train)\n",
    "\n",
    "predicted_charges = model.predict(X_test)\n",
    "# Outra maneira de calcular as métricas de erro é utilizando as funcións específicas de scikit-learn\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "mae = mean_absolute_error(Y_test, predicted_charges)\n",
    "mse = mean_squared_error(Y_test, predicted_charges)\n",
    "rmse = np.sqrt(mse)\n",
    "print(f\"Erro absoluto medio (MAE): {mae:.2f} dólares\")\n",
    "print(f\"Erro cadrático medio (MSE): {mse:.2f}\")\n",
    "print(f\"Raíz do erro cadrático medio (RMSE): {rmse:.2f} dólares\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9414840",
   "metadata": {},
   "source": [
    "Imos comparar o rendemento do modelo de regresión lineal múltiple con outros modelos de aprendizaxe automática, como os árbores de decisión e os bosques aleatorios."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1fab343",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeRegressor\n",
    "\n",
    "\n",
    "decision_tree_model = DecisionTreeRegressor(random_state=42)\n",
    "decision_tree_model.fit(X_train, Y_train)\n",
    "predicted_charges_tree = decision_tree_model.predict(X_test)\n",
    "mae_tree = mean_absolute_error(Y_test, predicted_charges_tree)\n",
    "mse_tree = mean_squared_error(Y_test, predicted_charges_tree)\n",
    "rmse_tree = np.sqrt(mse_tree)\n",
    "print(f\"Árbore de decisións - MAE: {mae_tree:.2f} dólares\")\n",
    "print(f\"Árbore de decisións - MSE: {mse_tree:.2f}\")\n",
    "print(f\"Árbore de decisións - RMSE: {rmse_tree:.2f} dólares\")\n",
    "\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "random_forest_model = RandomForestRegressor(random_state=42)\n",
    "random_forest_model.fit(X_train, Y_train)\n",
    "predicted_charges_forest = random_forest_model.predict(X_test)\n",
    "mae_forest = mean_absolute_error(Y_test, predicted_charges_forest)\n",
    "mse_forest = mean_squared_error(Y_test, predicted_charges_forest)\n",
    "rmse_forest = np.sqrt(mse_forest)\n",
    "print(f\"Bosque aleatorio - MAE: {mae_forest:.2f} dólares\")\n",
    "print(f\"Bosque aleatorio - MSE: {mse_forest:.2f}\")\n",
    "print(f\"Bosque aleatorio - RMSE: {rmse_forest:.2f} dólares\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56ace9bc",
   "metadata": {},
   "source": [
    "Se representamos as métricas de erro dos distintos modelos, podemos ver que o modelo de bosque aleatorio ten o mellor rendemento en todos os casos. É curioso que o modelo de regresión lineal ten un erro absoluto medio (MAE) maior que a árbore de decisión pero un erro cadrático medio (MSE) e unha raíz do erro cadrático medio (RMSE) menor. Isto indica que a árbore de decisión ten un rendemento mellor en media, pero os erros máis grandes teñen unha maior magnitude."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0be4e3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "error_metrics = {\n",
    "    'Modelo de regresión lineal': [mae, mse, rmse],\n",
    "    'Árbore de decisión': [mae_tree, mse_tree, rmse_tree],\n",
    "    'Bosque aleatorio': [mae_forest, mse_forest, rmse_forest]\n",
    "}\n",
    "metrics_names = ['MAE', 'MSE', 'RMSE']\n",
    "\n",
    "fig, axes = plt.subplots(1, 3, figsize=(15, 5))\n",
    "\n",
    "axes[0].bar(error_metrics.keys(), [error_metrics[model][0] for model in error_metrics.keys()])\n",
    "axes[0].set_title('MAE (Dólares)')\n",
    "axes[0].set_ylabel('Erro absoluto medio')\n",
    "axes[0].tick_params(axis='x', rotation=45)\n",
    "axes[0].grid(axis='y', linestyle='--', alpha=0.7)\n",
    "\n",
    "axes[1].bar(error_metrics.keys(), [error_metrics[model][1] for model in error_metrics.keys()])\n",
    "axes[1].set_title('MSE')\n",
    "axes[1].set_ylabel('Erro cadrático medio')\n",
    "axes[1].tick_params(axis='x', rotation=45)\n",
    "axes[1].grid(axis='y', linestyle='--', alpha=0.7)\n",
    "\n",
    "axes[2].bar(error_metrics.keys(), [error_metrics[model][2] for model in error_metrics.keys()])\n",
    "axes[2].set_title('RMSE (Dólares)')\n",
    "axes[2].set_ylabel('Raíz do erro cadrático medio')\n",
    "axes[2].tick_params(axis='x', rotation=45)\n",
    "axes[2].grid(axis='y', linestyle='--', alpha=0.7)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28ed2100",
   "metadata": {},
   "source": [
    "## Modelos de clasificación"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bb84c59",
   "metadata": {},
   "source": [
    "Os **modelos de clasificación** son un tipo de algoritmo de aprendizaxe automática supervisada que se utiliza para asignar unha etiqueta ou categoría a unha observación baseada en un conxunto de características. A diferenza dos modelos de regresión, que predín valores numéricos continuos, os modelos de clasificación predín categorías (valores discretos).\n",
    "\n",
    "Na medicina, os modelos de clasificación son amplamente utilizados para tarefas como:\n",
    "- **Diagnóstico de enfermidades**: Clasificar a presenza ou ausencia dunha enfermidade a partir de síntomas, resultados de probas ou imaxes médicas.\n",
    "- **Detección de tipos de cancro**: Identificar o tipo específico de cancro a partir de biopsias ou imaxes médicas.\n",
    "- **Triaxe de pacientes**: Clasificar a gravidade dos síntomas para priorizar o tratamento."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "746b2641",
   "metadata": {},
   "source": [
    "### Regresión loxística"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1195096",
   "metadata": {},
   "source": [
    "A **regresión loxística** é un modelo de clasificación que se utiliza para predecir a probabilidade de que unha observación pertenza a unha categoría específica. A diferenza da regresión lineal, a regresión loxística non predí valores numéricos continuos, senón probabilidades que van de 0 a 1.\n",
    "\n",
    "A fórmula da regresión loxística é:\n",
    "$$P(y=1|x) = \\frac{1}{1 + e^{-(\\beta_0 + \\beta_1 x_1 + \\beta_2 x_2 + ... + \\beta_n x_n)}}$$\n",
    "Onde:\n",
    "- $P(y=1|x)$ é a probabilidade de que a observación pertenza á categoría 1 (por exemplo, que un paciente teña unha enfermidade).\n",
    "- $x_1, x_2, ..., x_n$ son as variables independentes (características).\n",
    "- $\\beta_0$ é o termo independente ou constante (intercepto).\n",
    "- $\\beta_1, \\beta_2, ..., \\beta_n$ son os coeficientes que representan o efecto de cada variable independente sobre a probabilidade.\n",
    "\n",
    "En esencia, a regresión loxística é unha regresión lineal onde á saída se lle aplica unha función especial (chamada sigmoide) para garantir que os valores preditos estean entre 0 e 1.\n",
    "\n",
    "Un posible modelo de regresión loxística para predecir a probabilidade de que un paciente teña diabetes a partir da súa idade e do seu índice de masa corporal (IMC) podería ser:\n",
    "$$P(\\text{Diabetes}=1|\\text{Idade}, \\text{IMC}) = \\frac{1}{1 + e^{-(\\beta_0 + \\beta_1 \\cdot \\text{Idade} + \\beta_2 \\cdot \\text{IMC})}}$$\n",
    "\n",
    "Se no caso anterior $\\beta_0=-5$, $\\beta_1=0.05$ e $\\beta_2=0.1$, a probabilidade de que un paciente de 50 anos con IMC de 30 teña diabetes sería:\n",
    "$$P(\\text{Diabetes}=1|50, 30) = \\frac{1}{1 + e^{-(-5 + 0.05 \\cdot 50 + 0.1 \\cdot 30)}} = \\frac{1}{1 + e^{-0.5}} \\approx 0.62$$\n",
    "Isto significa que hai un 62% de probabilidade de que o paciente teña diabetes.\n",
    "\n",
    "A maneira de axustar automaticamente os parámetros dun modelo de regresión loxística é semellante á da regresión lineal, utilizando a biblioteca `scikit-learn`. Neste caso utilizamos a clase `LogisticRegression` para crear o modelo. Imos velo con un conxunto de datos simulado."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f78025fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simulamos os datos de adestramento: idade e imc como variables indpendentes (numéricas) e diabetes como variable dependente (binaria)\n",
    "n = 1000\n",
    "age = np.random.uniform(low=18, high=90, size=n)\n",
    "imc = np.random.uniform(low=18, high=27, size=n)\n",
    "logit = -10 + 0.08 * age + 0.18 * imc \n",
    "prob_diabetes = 1 / (1 + np.exp(-logit))\n",
    "diabetes = np.random.binomial(1, prob_diabetes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55a57682",
   "metadata": {},
   "source": [
    "Ahora formateamos o conxunto de datos para que sexa compatible co modelo de regresión loxística, separamos os conxuntos de adestramento e validación, e axustamos o modelo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d83d751",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.column_stack((age, imc))\n",
    "y = diabetes\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "logistic_model = LogisticRegression()\n",
    "logistic_model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51fca879",
   "metadata": {},
   "source": [
    "Do mesmo xeito que coa regresión lineal, podemos obter as predicións do modelo no conxunto de validación."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30fcc1cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_diabetes = logistic_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8332215",
   "metadata": {},
   "source": [
    "O que cambia é a maneira de avaliar o rendemento do modelo. Neste caso, como estamos a tratar cun problema de clasificación, utilizamos métricas específicas para este tipo de tarefas. A maneira máis rápida e intuitiva de avaliar un modelo de clasificación é a través da **matriz de confusión**, que nos permite ver como se comporta o modelo en cada categoría. A matriz de confusión é unha táboa que compara as predicións do modelo coas etiquetas reais, mostrando os verdadeiros positivos, falsos positivos, verdadeiros negativos e falsos negativos.\n",
    "A matriz de confusión ten a seguinte forma:\n",
    "| Predicións / Reais | Positivo (1) | Negativo (0) |\n",
    "|---------------------|--------------|--------------|\n",
    "| **Positivo (1)**    | Verdadeiros positivos (TP) | Falsos negativos (FN) |\n",
    "| **Negativo (0)**    | Falsos positivos (FP) | Verdadeiros negativos (TN) |\n",
    "- **Verdadeiros positivos (TP)**: Predicións correctas de que a observación pertence á categoría positiva.\n",
    "- **Falsos negativos (FN)**: Predicións incorrectas de que a observación non pertence á categoría positiva, cando en realidade si pertence.\n",
    "- **Falsos positivos (FP)**: Predicións incorrectas de que a observación pertence á categoría positiva, cando en realidade non pertence.\n",
    "- **Verdadeiros negativos (TN)**: Predicións correctas de que a observación non pertence á categoría positiva."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2a0ccda",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "cm = confusion_matrix(y_test, predicted_diabetes)\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.imshow(cm, interpolation='nearest', cmap='Blues')\n",
    "plt.colorbar()\n",
    "plt.xticks(np.arange(2), ['Non diabetes', 'Diabetes'])\n",
    "plt.yticks(np.arange(2), ['Non diabetes', 'Diabetes'])\n",
    "plt.xlabel('Predición')\n",
    "plt.ylabel('Realidade')\n",
    "plt.title('Matriz de confusión')\n",
    "# Engadimos os valores da matriz de confusión no mapa de calor\n",
    "for i in range(2):\n",
    "    for j in range(2):\n",
    "        plt.text(j, i, cm[i, j], ha='center', va='center', color='white' if cm[i, j] > cm.max() / 2 else 'black')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc8ccabe",
   "metadata": {},
   "source": [
    "A simple vista, podemos sacar varias conclusións:\n",
    "- O modelo é capaz de identificar razonablemente ben aos pacientes sen diabetes (131 identificacións correctas e 15 incorrectas)\n",
    "- O modelo confúndese á hora de identificar aos pacientes con diabetes (28 identificacións correctas e 26 incorrectas)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adf16f30",
   "metadata": {},
   "source": [
    "A partir desta matriz, podemos calcular distintas métricas de rendemento do modelo de clasificación:\n",
    "- **Exactitude (*Accuracy*)**: A proporción de predicións correctas sobre o total de predicións feitas. Indica que tan ben o modelo clasifica as observacións.\n",
    "$$\\text{Exactitude} = \\frac{\\text{Número de predicións correctas}}{\\text{Total de predicións}}$$\n",
    "- **Exhaustividade (*Recall*)**: A proporción de casos positivos correctamente identificados polo modelo sobre o total de casos positivos reais. Indica que tan ben o modelo detecta os casos positivos.\n",
    "$$\\text{Exhaustividade} = \\frac{\\text{Verdadeiros positivos}}{\\text{Verdadeiros positivos} + \\text{Falsos negativos}}$$\n",
    "- **Precisión (*Precision*)**: A proporción de casos positivos correctamente identificados polo modelo sobre o total de casos que o modelo clasificou como positivos. Indica que tan ben o modelo evita clasificar falsamente casos negativos como positivos.\n",
    "$$\\text{Precisión} = \\frac{\\text{Verdadeiros positivos}}{\\text{Verdadeiros positivos} + \\text{Falsos positivos}}$$\n",
    "- **F1-Score**: A media harmónica entre a precisión e a exhaustividade. É unha métrica que equilibra ambas as dúas, especialmente útil cando hai un desbalance entre as clases.\n",
    "\n",
    "Imos calcular estas métricas para o modelo de regresión loxística que axustamos anteriormente. Pero en vez de facer os cálculos manualmente, imos utilizar a función `classification_report` de `scikit-learn`, que nos proporciona un informe detallado das métricas de rendemento."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f3bf34b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "report = classification_report(y_test, predicted_diabetes, target_names=['Non diabetes', 'Diabetes'])\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc884825",
   "metadata": {},
   "source": [
    "Destas métricas podemos confirmar o que xa vimos na matriz de confusión, que o modelo falla ao detectar aos pacientes con diabetes. Neste caso particular, sería preferible detectar máis falsos positivos (pacientes que o modelo identifica como diabéticos pero que non o son) que falsos negativos (pacientes que o modelo identifica como non diabéticos pero que si o son), xa que un falso negativo podería levar a unha falta de diagnóstico e tratamento adecuado para a diabetes, mentres que un falso positivo podería levar a un seguimento innecesario pero non tan grave."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "collage",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
